dataset_params:
  load_latents: False
  condition_types: ["context_class"]
  z_channels: 4
  lpips_path: /workspace/results/models/LPIPS/vgg.pth
  target: dataset.Embryo_loader.Embryo_loader
  directory_inception_features: /workspace/data/inception_features
  latent_size: 64
  params:
    csv_file: /workspace/data/bbdd/final_ground_truth_MIUA/ground_truth_v2_train.csv
    root_dir: /workspace/data/images
    im_channels: 3


vqvae:
  load_checkpoint: True
  checkpoint_path_model: 'custom_vae_checkpoint/vqvae_autoencoder_ckpt.pth'
  checkpoint_path_discriminator: '/workspace/results/embryo/vqvae_discriminator_ckpt.pth'
  target: models.vqvae.VQVAE
  params:
    im_channels: 4
    z_channels: 4
    codebook_size: 8192
    down_channels: [ 64, 128, 256, 256 ]
    mid_channels: [ 256, 256 ]
    down_sample: [ True, True, True ]
    attns: [ False, False, False ]
    norm_channels: 32
    num_heads: 16
    num_down_layers: 2
    num_mid_layers: 2
    num_up_layers: 2


unet:
  target: models.unet_cond_base.Unet
  params:
    im_channels: 4
    down_channels: [256, 320, 384, 512]
    mid_channels: [ 512, 384]
    down_sample: [ True, True, True ]
    attns: [ True, True, True ]
    t_emb_dim: 512
    norm_channels: 32
    num_heads: 8
    conv_out_channels: 128
    num_down_layers: 2
    num_mid_layers: 1
    num_up_layers: 2
    condition_types:
      type_cond: [ "context_class" ]
      text_condition_config:
        text_embed_model: 'biobert'
        train_text_embed_model: False
        text_embed_dim: 512
        cond_drop_prob: 0.2
      class_condition_config:
        num_classes: 2
        class_labels: [ "Blastocist false", "Blastocist True" ]
        cond_drop_prob: 0.2  # Incrementar probabilidad de dropout
      context_class_config:
        num_classes: 2
        context_dim: 512
        class_labels: [ "Blastocist false", "Blastocist True" ]
        cond_drop_prob: 0.2  # Incrementar probabilidad de dropout

discriminator:
  target: models.discriminator.Discriminator
  params:
    im_channels: 4


diffusion_params:
  num_timesteps : 1000
  beta_start : 0.0015
  beta_end : 0.0195

ldm_params:
  down_channels: [ 256, 384, 512, 768 ]
  mid_channels: [ 768, 512 ]
  down_sample: [ True, True, True ]
  attn_down : [True, True, True]
  time_emb_dim: 512
  norm_channels: 32
  num_heads: 16
  conv_out_channels : 128
  num_down_layers : 2
  num_mid_layers : 2
  num_up_layers : 2

autoencoder_params:
  z_channels: 4
  codebook_size : 8192
  down_channels : [64, 128, 256, 256]
  mid_channels : [256, 256]
  down_sample : [True, True, True]
  attn_down : [False, False, False]
  norm_channels: 32
  num_heads: 4
  num_down_layers : 2
  num_mid_layers : 2
  num_up_layers : 2


train_params:
  seed : 1111
  task_name: '/workspace/results/output'
  ldm_batch_size: 24
  autoencoder_batch_size: 16
  disc_start: 15000
  disc_weight: 0.5
  codebook_weight: 1
  commitment_beta: 0.2
  perceptual_weight: 1
  kl_weight: 0.000005
  ldm_epochs: 120
  autoencoder_epochs: 300
  num_samples: 4
  num_grid_rows: 1
  ldm_validate_epochs: 4
  ldm_lr: 0.0005
  autoencoder_lr: 0.00001
  autoencoder_acc_steps: 4
  autoencoder_img_save_steps: 64
  save_latents : False
  vae_latent_dir_name: 'vae_latents'
  vqvae_latent_dir_name: 'vqvae_latents'
  ldm_ckpt_name: 'best_ddpm_ckpt.pth'
  vqvae_autoencoder_ckpt_name: 'vqvae_autoencoder_ckpt.pth'
  vae_autoencoder_ckpt_name: 'vae_autoencoder_ckpt.pth'
  vqvae_discriminator_ckpt_name: 'vqvae_discriminator_ckpt.pth'
  vae_discriminator_ckpt_name: 'vae_discriminator_ckpt.pth'
  resume_training: True
